{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed5ea81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Dropout, Flatten, Dense, \\\n",
    "    GlobalAveragePooling2D\n",
    "from tensorflow.keras import Model\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d63b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape (8800, 12, 12, 1)\n",
      "x_train.shape (2200, 12, 12, 1)\n"
     ]
    }
   ],
   "source": [
    "all_df=pd.read_csv(\"E:\\data\\multiclass\\multiclass\\data9.1.csv\")\n",
    "tr_Y = all_df['marker']\n",
    "tr_X = all_df.drop('marker', axis=1)\n",
    "sm = BorderlineSMOTE(random_state=42,kind=\"borderline-1\")\n",
    "tr_X, tr_Y = sm.fit_resample(tr_X, tr_Y)\n",
    "all_df=pd.concat([tr_X,tr_Y],axis=1)\n",
    "ndarray = all_df.values\n",
    "#把特征和标签分开用于归一化\n",
    "label=ndarray[:,-1].reshape(ndarray.shape[0],1)\n",
    "feature=ndarray[:,:-1]\n",
    "from sklearn import preprocessing\n",
    "#数据归一化\n",
    "minmax_scale=preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "scalefeature=minmax_scale.fit_transform(feature)\n",
    "#先将数据集进行拼接，要不然我们只针对样本进行采样的话，会找不到对应的标签的\n",
    "data = np.hstack((scalefeature,label))\n",
    "#使用随机采样方式划分数据集\n",
    "train_set,test_set = train_test_split(data,test_size = 0.2,random_state = 42)\n",
    "n=len(train_set)\n",
    "m=len(test_set)\n",
    "#把训练和测试的特征和标签分开\n",
    "tr_feature=train_set[:,:-1]\n",
    "tr_label=train_set[:,-1].reshape(n,1)\n",
    "te_feature=test_set[:,:-1]\n",
    "te_label=test_set[:,-1].reshape(m,1)\n",
    "\n",
    "b=np.zeros(tr_feature.shape[0]*16).reshape(tr_feature.shape[0],16)\n",
    "a=np.hstack((tr_feature,b)).reshape(tr_feature.shape[0],12,12)\n",
    "# 给数据增加一个维度，使数据和网络结构匹配\n",
    "x_train = a.reshape(a.shape[0], 12, 12, 1)\n",
    "#x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "print(\"x_train.shape\", x_train.shape)\n",
    "tr_label=tr_label.astype(np.uint8)\n",
    "b=np.zeros(te_feature.shape[0]*16).reshape(te_feature.shape[0],16)\n",
    "a=np.hstack((te_feature,b)).reshape(te_feature.shape[0],12,12)\n",
    "# 给数据增加一个维度，使数据和网络结构匹配\n",
    "x_test = a.reshape(a.shape[0], 12, 12, 1)\n",
    "#x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "print(\"x_train.shape\", x_test.shape)\n",
    "te_label=te_label[:,-1].astype(np.uint8)\n",
    "\n",
    "class ConvBNRelu(Model):\n",
    "    def __init__(self, ch, kernelsz=3, strides=1, padding='same'):\n",
    "        super(ConvBNRelu, self).__init__()\n",
    "        self.model = tf.keras.models.Sequential([\n",
    "            Conv2D(ch, kernelsz, strides=strides, padding=padding),\n",
    "            \n",
    "            BatchNormalization(),\n",
    "            Activation('relu')\n",
    "        ])\n",
    "\n",
    "    def call(self, x): \n",
    "        #在training=False时，BN通过整个训练集计算均值、方差去做批归一化，training=True时，通过当前batch的均值、方差去做批归一化。推理时 training=False效果好\n",
    "        x = self.model(x, training=False)\n",
    "        return x\n",
    "    \n",
    "#通过设定少于输入特征图深度的1*1卷积核个数减少了特征图深度，起到了降维的作用\n",
    "class InceptionBlk(Model):\n",
    "    def __init__(self, ch, strides=1):\n",
    "        super(InceptionBlk, self).__init__()\n",
    "        self.ch = ch\n",
    "        self.strides = strides\n",
    "        #第一分支：16个1*1卷积核，步长为1，全0填充\n",
    "        self.c1 = ConvBNRelu(ch, kernelsz=1, strides=strides)\n",
    "        #第二分支：16个1*1卷积核降维和16个3*3卷积核\n",
    "        self.c2_1 = ConvBNRelu(ch, kernelsz=1, strides=strides)\n",
    "        self.c2_2 = ConvBNRelu(ch, kernelsz=3, strides=1)\n",
    "        #第三分支：16个1*1卷积核降维和16个5*5卷积核\n",
    "        self.c3_1 = ConvBNRelu(ch, kernelsz=1, strides=strides)\n",
    "        self.c3_2 = ConvBNRelu(ch, kernelsz=5, strides=1)\n",
    "        #第四分支：3*3最大池化核和16个1*1卷积核降维\n",
    "        self.p4_1 = MaxPool2D(3, strides=1, padding='same')\n",
    "        self.c4_2 = ConvBNRelu(ch, kernelsz=1, strides=strides)\n",
    "\n",
    "    def call(self, x):\n",
    "        x1 = self.c1(x)\n",
    "        x2_1 = self.c2_1(x)\n",
    "        x2_2 = self.c2_2(x2_1)\n",
    "        x3_1 = self.c3_1(x)\n",
    "        x3_2 = self.c3_2(x3_1)\n",
    "        x4_1 = self.p4_1(x)\n",
    "        x4_2 = self.c4_2(x4_1)\n",
    "        \n",
    "        #卷积连接器，按深度方向堆叠构成inception结构块的输出\n",
    "        x = tf.concat([x1, x2_2, x3_2, x4_2], axis=3)\n",
    "        return x\n",
    "\n",
    "class Inception10(Model):\n",
    "    def __init__(self, num_blocks, num_classes, init_ch=16, **kwargs):\n",
    "        super(Inception10, self).__init__(**kwargs)\n",
    "        self.in_channels = init_ch\n",
    "        self.out_channels = init_ch\n",
    "        self.num_blocks = num_blocks\n",
    "        self.init_ch = init_ch\n",
    "        #网络第一层，16个3*3卷积核\n",
    "        self.c1 = ConvBNRelu(init_ch)\n",
    "        self.blocks = tf.keras.models.Sequential()\n",
    "        #4个inception结构块顺序相连，每两个结构块组成一个block\n",
    "        for block_id in range(num_blocks):\n",
    "            #block_0设置的通道数为16，经过四个分支输出的深度为4*16=64\n",
    "            #block_1的通道数是32，经过四个分支输出深度是4*32=128\n",
    "            for layer_id in range(2):\n",
    "                if layer_id == 0:\n",
    "                    #每个block中的第一个inception结构块卷积步长是2，输出特征图尺寸减半\n",
    "                    block = InceptionBlk(self.out_channels, strides=2)\n",
    "                else:\n",
    "                    #第二个inception结构块卷积步长是1\n",
    "                    block = InceptionBlk(self.out_channels, strides=1)\n",
    "                self.blocks.add(block)\n",
    "            #加深输出特征图深度，尽可能保证特征抽取中信息的承载量一致\n",
    "            #通道数加倍，故block_1通道数是block_0通道数两倍\n",
    "            self.out_channels *= 2\n",
    "        #平均池化\n",
    "        self.p1 = GlobalAveragePooling2D()\n",
    "        #5个分类的全连接\n",
    "        self.f1 = Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.c1(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.p1(x)\n",
    "        y = self.f1(x)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbde348f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8800 samples, validate on 2200 samples\n",
      "Epoch 1/200\n",
      "8800/8800 [==============================] - 12s 1ms/sample - loss: 1.4985 - sparse_categorical_accuracy: 0.3143 - val_loss: 1.4381 - val_sparse_categorical_accuracy: 0.3241\n",
      "Epoch 2/200\n",
      "8800/8800 [==============================] - 10s 1ms/sample - loss: 1.3056 - sparse_categorical_accuracy: 0.4445 - val_loss: 1.2246 - val_sparse_categorical_accuracy: 0.4886\n",
      "Epoch 3/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 1.1343 - sparse_categorical_accuracy: 0.5305 - val_loss: 1.0683 - val_sparse_categorical_accuracy: 0.5605\n",
      "Epoch 4/200\n",
      "8800/8800 [==============================] - 10s 1ms/sample - loss: 1.0031 - sparse_categorical_accuracy: 0.5935 - val_loss: 0.9406 - val_sparse_categorical_accuracy: 0.6168\n",
      "Epoch 5/200\n",
      "8800/8800 [==============================] - 10s 1ms/sample - loss: 0.9076 - sparse_categorical_accuracy: 0.6318 - val_loss: 0.8606 - val_sparse_categorical_accuracy: 0.6436\n",
      "Epoch 6/200\n",
      "8800/8800 [==============================] - 10s 1ms/sample - loss: 0.8043 - sparse_categorical_accuracy: 0.6740 - val_loss: 0.8194 - val_sparse_categorical_accuracy: 0.6727\n",
      "Epoch 7/200\n",
      "8800/8800 [==============================] - 10s 1ms/sample - loss: 0.7217 - sparse_categorical_accuracy: 0.7077 - val_loss: 0.6939 - val_sparse_categorical_accuracy: 0.7386\n",
      "Epoch 8/200\n",
      "8800/8800 [==============================] - 10s 1ms/sample - loss: 0.6664 - sparse_categorical_accuracy: 0.7333 - val_loss: 0.6933 - val_sparse_categorical_accuracy: 0.7114\n",
      "Epoch 9/200\n",
      "8800/8800 [==============================] - 10s 1ms/sample - loss: 0.6150 - sparse_categorical_accuracy: 0.7506 - val_loss: 0.5957 - val_sparse_categorical_accuracy: 0.7559\n",
      "Epoch 10/200\n",
      "8800/8800 [==============================] - 10s 1ms/sample - loss: 0.5777 - sparse_categorical_accuracy: 0.7680 - val_loss: 0.6268 - val_sparse_categorical_accuracy: 0.7450\n",
      "Epoch 11/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.5462 - sparse_categorical_accuracy: 0.7785 - val_loss: 0.5734 - val_sparse_categorical_accuracy: 0.7564\n",
      "Epoch 12/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.5018 - sparse_categorical_accuracy: 0.7987 - val_loss: 0.5456 - val_sparse_categorical_accuracy: 0.7727\n",
      "Epoch 13/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.4716 - sparse_categorical_accuracy: 0.8112 - val_loss: 0.5244 - val_sparse_categorical_accuracy: 0.7832\n",
      "Epoch 14/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.4505 - sparse_categorical_accuracy: 0.8175 - val_loss: 0.5899 - val_sparse_categorical_accuracy: 0.7618\n",
      "Epoch 15/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.4352 - sparse_categorical_accuracy: 0.8226 - val_loss: 0.5360 - val_sparse_categorical_accuracy: 0.7755\n",
      "Epoch 16/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.4124 - sparse_categorical_accuracy: 0.8326 - val_loss: 0.4837 - val_sparse_categorical_accuracy: 0.7982\n",
      "Epoch 17/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.3898 - sparse_categorical_accuracy: 0.8427 - val_loss: 0.4855 - val_sparse_categorical_accuracy: 0.8205\n",
      "Epoch 18/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.3935 - sparse_categorical_accuracy: 0.8385 - val_loss: 0.4921 - val_sparse_categorical_accuracy: 0.8100\n",
      "Epoch 19/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.3645 - sparse_categorical_accuracy: 0.8508 - val_loss: 0.4422 - val_sparse_categorical_accuracy: 0.8418\n",
      "Epoch 20/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.3557 - sparse_categorical_accuracy: 0.8607 - val_loss: 0.4687 - val_sparse_categorical_accuracy: 0.8205\n",
      "Epoch 21/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.3411 - sparse_categorical_accuracy: 0.8634 - val_loss: 0.4093 - val_sparse_categorical_accuracy: 0.8514\n",
      "Epoch 22/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.3373 - sparse_categorical_accuracy: 0.8630 - val_loss: 0.4074 - val_sparse_categorical_accuracy: 0.8577\n",
      "Epoch 23/200\n",
      "8800/8800 [==============================] - 10s 1ms/sample - loss: 0.3179 - sparse_categorical_accuracy: 0.8737 - val_loss: 0.4141 - val_sparse_categorical_accuracy: 0.8450\n",
      "Epoch 24/200\n",
      "8800/8800 [==============================] - 10s 1ms/sample - loss: 0.3020 - sparse_categorical_accuracy: 0.8793 - val_loss: 0.4063 - val_sparse_categorical_accuracy: 0.8641\n",
      "Epoch 25/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.3015 - sparse_categorical_accuracy: 0.8782 - val_loss: 0.3714 - val_sparse_categorical_accuracy: 0.8718\n",
      "Epoch 26/200\n",
      "8800/8800 [==============================] - 10s 1ms/sample - loss: 0.2952 - sparse_categorical_accuracy: 0.8810 - val_loss: 0.3804 - val_sparse_categorical_accuracy: 0.8614\n",
      "Epoch 27/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.2908 - sparse_categorical_accuracy: 0.8848 - val_loss: 0.3621 - val_sparse_categorical_accuracy: 0.8686\n",
      "Epoch 28/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.2674 - sparse_categorical_accuracy: 0.8934 - val_loss: 0.5540 - val_sparse_categorical_accuracy: 0.8041\n",
      "Epoch 29/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.2794 - sparse_categorical_accuracy: 0.8891 - val_loss: 0.3846 - val_sparse_categorical_accuracy: 0.8655\n",
      "Epoch 30/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.2631 - sparse_categorical_accuracy: 0.8949 - val_loss: 0.4263 - val_sparse_categorical_accuracy: 0.8500\n",
      "Epoch 31/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.2582 - sparse_categorical_accuracy: 0.8960 - val_loss: 0.4115 - val_sparse_categorical_accuracy: 0.8564\n",
      "Epoch 32/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.2638 - sparse_categorical_accuracy: 0.8938 - val_loss: 0.4175 - val_sparse_categorical_accuracy: 0.8623\n",
      "Epoch 33/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.2493 - sparse_categorical_accuracy: 0.9008 - val_loss: 0.3475 - val_sparse_categorical_accuracy: 0.8809\n",
      "Epoch 34/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.2489 - sparse_categorical_accuracy: 0.9010 - val_loss: 0.3505 - val_sparse_categorical_accuracy: 0.8695\n",
      "Epoch 35/200\n",
      "8800/8800 [==============================] - 10s 1ms/sample - loss: 0.2370 - sparse_categorical_accuracy: 0.9041 - val_loss: 0.3924 - val_sparse_categorical_accuracy: 0.8682\n",
      "Epoch 36/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.2446 - sparse_categorical_accuracy: 0.9007 - val_loss: 0.3448 - val_sparse_categorical_accuracy: 0.8923\n",
      "Epoch 37/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.2337 - sparse_categorical_accuracy: 0.9062 - val_loss: 0.3188 - val_sparse_categorical_accuracy: 0.8927\n",
      "Epoch 38/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.2369 - sparse_categorical_accuracy: 0.9058 - val_loss: 0.3475 - val_sparse_categorical_accuracy: 0.8732\n",
      "Epoch 39/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.2285 - sparse_categorical_accuracy: 0.9091 - val_loss: 0.4488 - val_sparse_categorical_accuracy: 0.8382\n",
      "Epoch 40/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.2318 - sparse_categorical_accuracy: 0.9078 - val_loss: 0.3487 - val_sparse_categorical_accuracy: 0.8936\n",
      "Epoch 41/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.2166 - sparse_categorical_accuracy: 0.9148 - val_loss: 0.3269 - val_sparse_categorical_accuracy: 0.8877\n",
      "Epoch 42/200\n",
      "8800/8800 [==============================] - 10s 1ms/sample - loss: 0.2159 - sparse_categorical_accuracy: 0.9140 - val_loss: 0.3401 - val_sparse_categorical_accuracy: 0.8727\n",
      "Epoch 43/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.2228 - sparse_categorical_accuracy: 0.9124 - val_loss: 0.4066 - val_sparse_categorical_accuracy: 0.8659\n",
      "Epoch 44/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.2146 - sparse_categorical_accuracy: 0.9143 - val_loss: 0.3382 - val_sparse_categorical_accuracy: 0.8855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.2018 - sparse_categorical_accuracy: 0.9200 - val_loss: 0.3451 - val_sparse_categorical_accuracy: 0.8845\n",
      "Epoch 46/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.2086 - sparse_categorical_accuracy: 0.9182 - val_loss: 0.3780 - val_sparse_categorical_accuracy: 0.8923\n",
      "Epoch 47/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.2007 - sparse_categorical_accuracy: 0.9202 - val_loss: 0.3237 - val_sparse_categorical_accuracy: 0.8873\n",
      "Epoch 48/200\n",
      "8800/8800 [==============================] - 10s 1ms/sample - loss: 0.2094 - sparse_categorical_accuracy: 0.9173 - val_loss: 0.3314 - val_sparse_categorical_accuracy: 0.8859\n",
      "Epoch 49/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1910 - sparse_categorical_accuracy: 0.9257 - val_loss: 0.3538 - val_sparse_categorical_accuracy: 0.8759\n",
      "Epoch 50/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1823 - sparse_categorical_accuracy: 0.9282 - val_loss: 0.3633 - val_sparse_categorical_accuracy: 0.8886\n",
      "Epoch 51/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1910 - sparse_categorical_accuracy: 0.9262 - val_loss: 0.3430 - val_sparse_categorical_accuracy: 0.8850\n",
      "Epoch 52/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1971 - sparse_categorical_accuracy: 0.9245 - val_loss: 0.3280 - val_sparse_categorical_accuracy: 0.8836\n",
      "Epoch 53/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1822 - sparse_categorical_accuracy: 0.9260 - val_loss: 0.3942 - val_sparse_categorical_accuracy: 0.8723\n",
      "Epoch 54/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1913 - sparse_categorical_accuracy: 0.9243 - val_loss: 0.3466 - val_sparse_categorical_accuracy: 0.8795\n",
      "Epoch 55/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1934 - sparse_categorical_accuracy: 0.9250 - val_loss: 0.3611 - val_sparse_categorical_accuracy: 0.8809\n",
      "Epoch 56/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1878 - sparse_categorical_accuracy: 0.9244 - val_loss: 0.3714 - val_sparse_categorical_accuracy: 0.8732\n",
      "Epoch 57/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1773 - sparse_categorical_accuracy: 0.9290 - val_loss: 0.3431 - val_sparse_categorical_accuracy: 0.8882\n",
      "Epoch 58/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1875 - sparse_categorical_accuracy: 0.9250 - val_loss: 0.3258 - val_sparse_categorical_accuracy: 0.9041\n",
      "Epoch 59/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1757 - sparse_categorical_accuracy: 0.9299 - val_loss: 0.2869 - val_sparse_categorical_accuracy: 0.9177\n",
      "Epoch 60/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1671 - sparse_categorical_accuracy: 0.9350 - val_loss: 0.2859 - val_sparse_categorical_accuracy: 0.9168\n",
      "Epoch 61/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1604 - sparse_categorical_accuracy: 0.9397 - val_loss: 0.3308 - val_sparse_categorical_accuracy: 0.8932\n",
      "Epoch 62/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1737 - sparse_categorical_accuracy: 0.9331 - val_loss: 0.2948 - val_sparse_categorical_accuracy: 0.9118\n",
      "Epoch 63/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1761 - sparse_categorical_accuracy: 0.9325 - val_loss: 0.3126 - val_sparse_categorical_accuracy: 0.9082\n",
      "Epoch 64/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1576 - sparse_categorical_accuracy: 0.9374 - val_loss: 0.2863 - val_sparse_categorical_accuracy: 0.9177\n",
      "Epoch 65/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1740 - sparse_categorical_accuracy: 0.9349 - val_loss: 0.3219 - val_sparse_categorical_accuracy: 0.8941\n",
      "Epoch 66/200\n",
      "8800/8800 [==============================] - 10s 1ms/sample - loss: 0.1669 - sparse_categorical_accuracy: 0.9367 - val_loss: 0.3077 - val_sparse_categorical_accuracy: 0.9145\n",
      "Epoch 67/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1824 - sparse_categorical_accuracy: 0.9328 - val_loss: 0.2979 - val_sparse_categorical_accuracy: 0.9091\n",
      "Epoch 68/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1529 - sparse_categorical_accuracy: 0.9403 - val_loss: 0.3320 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 69/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1514 - sparse_categorical_accuracy: 0.9395 - val_loss: 0.2857 - val_sparse_categorical_accuracy: 0.9155\n",
      "Epoch 70/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1592 - sparse_categorical_accuracy: 0.9367 - val_loss: 0.3255 - val_sparse_categorical_accuracy: 0.9091\n",
      "Epoch 71/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1585 - sparse_categorical_accuracy: 0.9374 - val_loss: 0.3132 - val_sparse_categorical_accuracy: 0.8959\n",
      "Epoch 72/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1550 - sparse_categorical_accuracy: 0.9382 - val_loss: 0.2885 - val_sparse_categorical_accuracy: 0.9173\n",
      "Epoch 73/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1582 - sparse_categorical_accuracy: 0.9369 - val_loss: 0.3350 - val_sparse_categorical_accuracy: 0.9100\n",
      "Epoch 74/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1460 - sparse_categorical_accuracy: 0.9411 - val_loss: 0.3347 - val_sparse_categorical_accuracy: 0.9027\n",
      "Epoch 75/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1613 - sparse_categorical_accuracy: 0.9365 - val_loss: 0.2814 - val_sparse_categorical_accuracy: 0.9123\n",
      "Epoch 76/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1443 - sparse_categorical_accuracy: 0.9416 - val_loss: 0.3766 - val_sparse_categorical_accuracy: 0.8805\n",
      "Epoch 77/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1424 - sparse_categorical_accuracy: 0.9427 - val_loss: 0.3331 - val_sparse_categorical_accuracy: 0.8991\n",
      "Epoch 78/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1506 - sparse_categorical_accuracy: 0.9414 - val_loss: 0.2759 - val_sparse_categorical_accuracy: 0.9241\n",
      "Epoch 79/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1601 - sparse_categorical_accuracy: 0.9380 - val_loss: 0.2927 - val_sparse_categorical_accuracy: 0.9186\n",
      "Epoch 80/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1442 - sparse_categorical_accuracy: 0.9410 - val_loss: 0.2948 - val_sparse_categorical_accuracy: 0.9091\n",
      "Epoch 81/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1440 - sparse_categorical_accuracy: 0.9427 - val_loss: 0.2940 - val_sparse_categorical_accuracy: 0.9132\n",
      "Epoch 82/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1386 - sparse_categorical_accuracy: 0.9430 - val_loss: 0.3192 - val_sparse_categorical_accuracy: 0.9095\n",
      "Epoch 83/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1464 - sparse_categorical_accuracy: 0.9418 - val_loss: 0.3153 - val_sparse_categorical_accuracy: 0.9095\n",
      "Epoch 84/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1328 - sparse_categorical_accuracy: 0.9474 - val_loss: 0.3114 - val_sparse_categorical_accuracy: 0.9077\n",
      "Epoch 85/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1383 - sparse_categorical_accuracy: 0.9445 - val_loss: 0.3677 - val_sparse_categorical_accuracy: 0.9032\n",
      "Epoch 86/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1383 - sparse_categorical_accuracy: 0.9452 - val_loss: 0.3096 - val_sparse_categorical_accuracy: 0.9064\n",
      "Epoch 87/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1296 - sparse_categorical_accuracy: 0.9491 - val_loss: 0.2951 - val_sparse_categorical_accuracy: 0.9273\n",
      "Epoch 88/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1348 - sparse_categorical_accuracy: 0.9482 - val_loss: 0.3447 - val_sparse_categorical_accuracy: 0.9114\n",
      "Epoch 89/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1496 - sparse_categorical_accuracy: 0.9417 - val_loss: 0.3000 - val_sparse_categorical_accuracy: 0.9150\n",
      "Epoch 90/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1303 - sparse_categorical_accuracy: 0.9470 - val_loss: 0.3663 - val_sparse_categorical_accuracy: 0.8882\n",
      "Epoch 91/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1320 - sparse_categorical_accuracy: 0.9475 - val_loss: 0.3137 - val_sparse_categorical_accuracy: 0.9159\n",
      "Epoch 92/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1438 - sparse_categorical_accuracy: 0.9427 - val_loss: 0.3523 - val_sparse_categorical_accuracy: 0.9132\n",
      "Epoch 93/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1139 - sparse_categorical_accuracy: 0.9556 - val_loss: 0.3763 - val_sparse_categorical_accuracy: 0.9018\n",
      "Epoch 94/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1370 - sparse_categorical_accuracy: 0.9469 - val_loss: 0.4462 - val_sparse_categorical_accuracy: 0.8750\n",
      "Epoch 95/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1397 - sparse_categorical_accuracy: 0.9457 - val_loss: 0.3078 - val_sparse_categorical_accuracy: 0.9123\n",
      "Epoch 96/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1248 - sparse_categorical_accuracy: 0.9506 - val_loss: 0.3271 - val_sparse_categorical_accuracy: 0.9123\n",
      "Epoch 97/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1308 - sparse_categorical_accuracy: 0.9493 - val_loss: 0.4022 - val_sparse_categorical_accuracy: 0.9018\n",
      "Epoch 98/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1239 - sparse_categorical_accuracy: 0.9526 - val_loss: 0.3437 - val_sparse_categorical_accuracy: 0.9077\n",
      "Epoch 99/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1232 - sparse_categorical_accuracy: 0.9501 - val_loss: 0.3378 - val_sparse_categorical_accuracy: 0.9114\n",
      "Epoch 100/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1299 - sparse_categorical_accuracy: 0.9505 - val_loss: 0.2972 - val_sparse_categorical_accuracy: 0.9264\n",
      "Epoch 101/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1231 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.3572 - val_sparse_categorical_accuracy: 0.8964\n",
      "Epoch 102/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1321 - sparse_categorical_accuracy: 0.9505 - val_loss: 0.3716 - val_sparse_categorical_accuracy: 0.9155\n",
      "Epoch 103/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1226 - sparse_categorical_accuracy: 0.9515 - val_loss: 0.3354 - val_sparse_categorical_accuracy: 0.9173\n",
      "Epoch 104/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1340 - sparse_categorical_accuracy: 0.9501 - val_loss: 0.5834 - val_sparse_categorical_accuracy: 0.8741\n",
      "Epoch 105/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1362 - sparse_categorical_accuracy: 0.9499 - val_loss: 0.2674 - val_sparse_categorical_accuracy: 0.9318\n",
      "Epoch 106/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1237 - sparse_categorical_accuracy: 0.9505 - val_loss: 0.3493 - val_sparse_categorical_accuracy: 0.8927\n",
      "Epoch 107/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1228 - sparse_categorical_accuracy: 0.9535 - val_loss: 0.2827 - val_sparse_categorical_accuracy: 0.9295\n",
      "Epoch 108/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1223 - sparse_categorical_accuracy: 0.9522 - val_loss: 0.3470 - val_sparse_categorical_accuracy: 0.9009\n",
      "Epoch 109/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1211 - sparse_categorical_accuracy: 0.9541 - val_loss: 0.3356 - val_sparse_categorical_accuracy: 0.9086\n",
      "Epoch 110/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1284 - sparse_categorical_accuracy: 0.9497 - val_loss: 0.2816 - val_sparse_categorical_accuracy: 0.9218\n",
      "Epoch 111/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1289 - sparse_categorical_accuracy: 0.9492 - val_loss: 0.2718 - val_sparse_categorical_accuracy: 0.9282\n",
      "Epoch 112/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1195 - sparse_categorical_accuracy: 0.9510 - val_loss: 0.3431 - val_sparse_categorical_accuracy: 0.9091\n",
      "Epoch 113/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1085 - sparse_categorical_accuracy: 0.9558 - val_loss: 0.2914 - val_sparse_categorical_accuracy: 0.9350\n",
      "Epoch 114/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1128 - sparse_categorical_accuracy: 0.9569 - val_loss: 0.3038 - val_sparse_categorical_accuracy: 0.9282\n",
      "Epoch 115/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1323 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.3502 - val_sparse_categorical_accuracy: 0.9127\n",
      "Epoch 116/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1108 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.3343 - val_sparse_categorical_accuracy: 0.9186\n",
      "Epoch 117/200\n",
      "8800/8800 [==============================] - 10s 1ms/sample - loss: 0.1226 - sparse_categorical_accuracy: 0.9483 - val_loss: 0.3280 - val_sparse_categorical_accuracy: 0.9214\n",
      "Epoch 118/200\n",
      "8800/8800 [==============================] - 10s 1ms/sample - loss: 0.1224 - sparse_categorical_accuracy: 0.9544 - val_loss: 0.2893 - val_sparse_categorical_accuracy: 0.9273\n",
      "Epoch 119/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1045 - sparse_categorical_accuracy: 0.9580 - val_loss: 0.3473 - val_sparse_categorical_accuracy: 0.9136\n",
      "Epoch 120/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1161 - sparse_categorical_accuracy: 0.9539 - val_loss: 0.2750 - val_sparse_categorical_accuracy: 0.9364\n",
      "Epoch 121/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1246 - sparse_categorical_accuracy: 0.9499 - val_loss: 0.3515 - val_sparse_categorical_accuracy: 0.9209\n",
      "Epoch 122/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1201 - sparse_categorical_accuracy: 0.9544 - val_loss: 0.2764 - val_sparse_categorical_accuracy: 0.9300\n",
      "Epoch 123/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1046 - sparse_categorical_accuracy: 0.9598 - val_loss: 0.3344 - val_sparse_categorical_accuracy: 0.9145\n",
      "Epoch 124/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1145 - sparse_categorical_accuracy: 0.9544 - val_loss: 0.3205 - val_sparse_categorical_accuracy: 0.9273\n",
      "Epoch 125/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1078 - sparse_categorical_accuracy: 0.9561 - val_loss: 0.3118 - val_sparse_categorical_accuracy: 0.9255\n",
      "Epoch 126/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1165 - sparse_categorical_accuracy: 0.9544 - val_loss: 0.2930 - val_sparse_categorical_accuracy: 0.9318\n",
      "Epoch 127/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1005 - sparse_categorical_accuracy: 0.9618 - val_loss: 0.3528 - val_sparse_categorical_accuracy: 0.9168\n",
      "Epoch 128/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1246 - sparse_categorical_accuracy: 0.9533 - val_loss: 0.2980 - val_sparse_categorical_accuracy: 0.9268\n",
      "Epoch 129/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1160 - sparse_categorical_accuracy: 0.9553 - val_loss: 0.2908 - val_sparse_categorical_accuracy: 0.9332\n",
      "Epoch 130/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1080 - sparse_categorical_accuracy: 0.9582 - val_loss: 0.2826 - val_sparse_categorical_accuracy: 0.9318\n",
      "Epoch 131/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1044 - sparse_categorical_accuracy: 0.9564 - val_loss: 0.3923 - val_sparse_categorical_accuracy: 0.9055\n",
      "Epoch 132/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1051 - sparse_categorical_accuracy: 0.9600 - val_loss: 0.2955 - val_sparse_categorical_accuracy: 0.9232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1088 - sparse_categorical_accuracy: 0.9573 - val_loss: 0.3081 - val_sparse_categorical_accuracy: 0.9259\n",
      "Epoch 134/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1035 - sparse_categorical_accuracy: 0.9589 - val_loss: 0.3018 - val_sparse_categorical_accuracy: 0.9318\n",
      "Epoch 135/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1001 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.2773 - val_sparse_categorical_accuracy: 0.9359\n",
      "Epoch 136/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1072 - sparse_categorical_accuracy: 0.9570 - val_loss: 0.3164 - val_sparse_categorical_accuracy: 0.9273\n",
      "Epoch 137/200\n",
      "8800/8800 [==============================] - 10s 1ms/sample - loss: 0.1115 - sparse_categorical_accuracy: 0.9549 - val_loss: 0.2678 - val_sparse_categorical_accuracy: 0.9336\n",
      "Epoch 138/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1000 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.3191 - val_sparse_categorical_accuracy: 0.9182\n",
      "Epoch 139/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1059 - sparse_categorical_accuracy: 0.9599 - val_loss: 0.2676 - val_sparse_categorical_accuracy: 0.9345\n",
      "Epoch 140/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1031 - sparse_categorical_accuracy: 0.9578 - val_loss: 0.3338 - val_sparse_categorical_accuracy: 0.9118\n",
      "Epoch 141/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0940 - sparse_categorical_accuracy: 0.9631 - val_loss: 0.2823 - val_sparse_categorical_accuracy: 0.9377\n",
      "Epoch 142/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1154 - sparse_categorical_accuracy: 0.9572 - val_loss: 0.3804 - val_sparse_categorical_accuracy: 0.8995\n",
      "Epoch 143/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1035 - sparse_categorical_accuracy: 0.9577 - val_loss: 0.2986 - val_sparse_categorical_accuracy: 0.9341\n",
      "Epoch 144/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0893 - sparse_categorical_accuracy: 0.9640 - val_loss: 0.4051 - val_sparse_categorical_accuracy: 0.9014\n",
      "Epoch 145/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1213 - sparse_categorical_accuracy: 0.9509 - val_loss: 0.2989 - val_sparse_categorical_accuracy: 0.9259\n",
      "Epoch 146/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1016 - sparse_categorical_accuracy: 0.9584 - val_loss: 0.2907 - val_sparse_categorical_accuracy: 0.9305\n",
      "Epoch 147/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1025 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.3122 - val_sparse_categorical_accuracy: 0.9245\n",
      "Epoch 148/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1122 - sparse_categorical_accuracy: 0.9592 - val_loss: 0.3520 - val_sparse_categorical_accuracy: 0.9136\n",
      "Epoch 149/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0957 - sparse_categorical_accuracy: 0.9633 - val_loss: 0.2725 - val_sparse_categorical_accuracy: 0.9364\n",
      "Epoch 150/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0902 - sparse_categorical_accuracy: 0.9624 - val_loss: 0.3733 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 151/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1007 - sparse_categorical_accuracy: 0.9611 - val_loss: 0.2877 - val_sparse_categorical_accuracy: 0.9305\n",
      "Epoch 152/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1072 - sparse_categorical_accuracy: 0.9575 - val_loss: 0.2894 - val_sparse_categorical_accuracy: 0.9264\n",
      "Epoch 153/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0996 - sparse_categorical_accuracy: 0.9618 - val_loss: 0.2741 - val_sparse_categorical_accuracy: 0.9368\n",
      "Epoch 154/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0936 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.3263 - val_sparse_categorical_accuracy: 0.9305\n",
      "Epoch 155/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0972 - sparse_categorical_accuracy: 0.9623 - val_loss: 0.3117 - val_sparse_categorical_accuracy: 0.9273\n",
      "Epoch 156/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0835 - sparse_categorical_accuracy: 0.9648 - val_loss: 0.3453 - val_sparse_categorical_accuracy: 0.9214\n",
      "Epoch 157/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1112 - sparse_categorical_accuracy: 0.9577 - val_loss: 0.3028 - val_sparse_categorical_accuracy: 0.9241\n",
      "Epoch 158/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0909 - sparse_categorical_accuracy: 0.9658 - val_loss: 0.2996 - val_sparse_categorical_accuracy: 0.9277\n",
      "Epoch 159/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1033 - sparse_categorical_accuracy: 0.9589 - val_loss: 0.3231 - val_sparse_categorical_accuracy: 0.9273\n",
      "Epoch 160/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1046 - sparse_categorical_accuracy: 0.9598 - val_loss: 0.3094 - val_sparse_categorical_accuracy: 0.9336\n",
      "Epoch 161/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0960 - sparse_categorical_accuracy: 0.9623 - val_loss: 0.2643 - val_sparse_categorical_accuracy: 0.9382\n",
      "Epoch 162/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0931 - sparse_categorical_accuracy: 0.9641 - val_loss: 0.2535 - val_sparse_categorical_accuracy: 0.9323\n",
      "Epoch 163/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0956 - sparse_categorical_accuracy: 0.9628 - val_loss: 0.3361 - val_sparse_categorical_accuracy: 0.9191\n",
      "Epoch 164/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1008 - sparse_categorical_accuracy: 0.9619 - val_loss: 0.2608 - val_sparse_categorical_accuracy: 0.9386\n",
      "Epoch 165/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0959 - sparse_categorical_accuracy: 0.9653 - val_loss: 0.3013 - val_sparse_categorical_accuracy: 0.9268\n",
      "Epoch 166/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0863 - sparse_categorical_accuracy: 0.9652 - val_loss: 0.3083 - val_sparse_categorical_accuracy: 0.9332\n",
      "Epoch 167/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0947 - sparse_categorical_accuracy: 0.9639 - val_loss: 0.2964 - val_sparse_categorical_accuracy: 0.9300\n",
      "Epoch 168/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0980 - sparse_categorical_accuracy: 0.9619 - val_loss: 0.3110 - val_sparse_categorical_accuracy: 0.9336\n",
      "Epoch 169/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0850 - sparse_categorical_accuracy: 0.9655 - val_loss: 0.3029 - val_sparse_categorical_accuracy: 0.9227\n",
      "Epoch 170/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0973 - sparse_categorical_accuracy: 0.9623 - val_loss: 0.3060 - val_sparse_categorical_accuracy: 0.9314\n",
      "Epoch 171/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0882 - sparse_categorical_accuracy: 0.9656 - val_loss: 0.3139 - val_sparse_categorical_accuracy: 0.9177\n",
      "Epoch 172/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0993 - sparse_categorical_accuracy: 0.9615 - val_loss: 0.3154 - val_sparse_categorical_accuracy: 0.9255\n",
      "Epoch 173/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0991 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.2649 - val_sparse_categorical_accuracy: 0.9359\n",
      "Epoch 174/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0875 - sparse_categorical_accuracy: 0.9659 - val_loss: 0.3705 - val_sparse_categorical_accuracy: 0.9200\n",
      "Epoch 175/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0926 - sparse_categorical_accuracy: 0.9641 - val_loss: 0.2741 - val_sparse_categorical_accuracy: 0.9350\n",
      "Epoch 176/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0873 - sparse_categorical_accuracy: 0.9665 - val_loss: 0.2784 - val_sparse_categorical_accuracy: 0.9386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0928 - sparse_categorical_accuracy: 0.9657 - val_loss: 0.4491 - val_sparse_categorical_accuracy: 0.8832\n",
      "Epoch 178/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0941 - sparse_categorical_accuracy: 0.9631 - val_loss: 0.3284 - val_sparse_categorical_accuracy: 0.9327\n",
      "Epoch 179/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0874 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.3051 - val_sparse_categorical_accuracy: 0.9241\n",
      "Epoch 180/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0958 - sparse_categorical_accuracy: 0.9634 - val_loss: 0.2789 - val_sparse_categorical_accuracy: 0.9386\n",
      "Epoch 181/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0841 - sparse_categorical_accuracy: 0.9657 - val_loss: 0.3046 - val_sparse_categorical_accuracy: 0.9327\n",
      "Epoch 182/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.1026 - sparse_categorical_accuracy: 0.9605 - val_loss: 0.2829 - val_sparse_categorical_accuracy: 0.9327\n",
      "Epoch 183/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0721 - sparse_categorical_accuracy: 0.9718 - val_loss: 0.2963 - val_sparse_categorical_accuracy: 0.9400\n",
      "Epoch 184/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0948 - sparse_categorical_accuracy: 0.9673 - val_loss: 0.2684 - val_sparse_categorical_accuracy: 0.9377\n",
      "Epoch 185/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0920 - sparse_categorical_accuracy: 0.9663 - val_loss: 0.2843 - val_sparse_categorical_accuracy: 0.9273\n",
      "Epoch 186/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0909 - sparse_categorical_accuracy: 0.9640 - val_loss: 0.2917 - val_sparse_categorical_accuracy: 0.9318\n",
      "Epoch 187/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0778 - sparse_categorical_accuracy: 0.9675 - val_loss: 0.3107 - val_sparse_categorical_accuracy: 0.9300\n",
      "Epoch 188/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0909 - sparse_categorical_accuracy: 0.9631 - val_loss: 0.3471 - val_sparse_categorical_accuracy: 0.9209\n",
      "Epoch 189/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0876 - sparse_categorical_accuracy: 0.9672 - val_loss: 0.3639 - val_sparse_categorical_accuracy: 0.9082\n",
      "Epoch 190/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0926 - sparse_categorical_accuracy: 0.9628 - val_loss: 0.2688 - val_sparse_categorical_accuracy: 0.9386\n",
      "Epoch 191/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0801 - sparse_categorical_accuracy: 0.9680 - val_loss: 0.2798 - val_sparse_categorical_accuracy: 0.9295\n",
      "Epoch 192/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0932 - sparse_categorical_accuracy: 0.9618 - val_loss: 0.2847 - val_sparse_categorical_accuracy: 0.9441\n",
      "Epoch 193/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0981 - sparse_categorical_accuracy: 0.9610 - val_loss: 0.2710 - val_sparse_categorical_accuracy: 0.9377\n",
      "Epoch 194/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0701 - sparse_categorical_accuracy: 0.9722 - val_loss: 0.2974 - val_sparse_categorical_accuracy: 0.9259\n",
      "Epoch 195/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0870 - sparse_categorical_accuracy: 0.9669 - val_loss: 0.2727 - val_sparse_categorical_accuracy: 0.9309\n",
      "Epoch 196/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0874 - sparse_categorical_accuracy: 0.9665 - val_loss: 0.2739 - val_sparse_categorical_accuracy: 0.9345\n",
      "Epoch 197/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0859 - sparse_categorical_accuracy: 0.9664 - val_loss: 0.3094 - val_sparse_categorical_accuracy: 0.9405\n",
      "Epoch 198/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0844 - sparse_categorical_accuracy: 0.9657 - val_loss: 0.2557 - val_sparse_categorical_accuracy: 0.9464\n",
      "Epoch 199/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0922 - sparse_categorical_accuracy: 0.9638 - val_loss: 0.2946 - val_sparse_categorical_accuracy: 0.9345\n",
      "Epoch 200/200\n",
      "8800/8800 [==============================] - 9s 1ms/sample - loss: 0.0850 - sparse_categorical_accuracy: 0.9661 - val_loss: 0.2894 - val_sparse_categorical_accuracy: 0.9373\n",
      "Model: \"inception10_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_bn_relu_25 (ConvBNRelu) multiple                  224       \n",
      "_________________________________________________________________\n",
      "sequential_27 (Sequential)   multiple                  119616    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  645       \n",
      "=================================================================\n",
      "Total params: 120,485\n",
      "Trainable params: 119,301\n",
      "Non-trainable params: 1,184\n",
      "_________________________________________________________________\n",
      "1889.5590989589691\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model = Inception10(num_blocks=2, num_classes=5)\n",
    "#编译模型\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "\n",
    "#filepath=\"CNN_best_weights.{epoch:02d}-{val_sparse_categorical_accuracy:.4f}.hdf5\"\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='val_sparse_categorical_accuracy', verbose=1, \n",
    "#                              save_weights_only=True, save_best_only=True, mode='max')\n",
    "\n",
    "#validation_data指定测试集，validation_freq指定测试频率（多少epoch进行一次验证）\n",
    "history = model.fit(x_train, tr_label, batch_size=10, epochs=200, validation_data=(x_test, te_label))\n",
    "\n",
    "\n",
    "#输出模型各层的参数状况\n",
    "model.summary()\n",
    "\n",
    "time_used = time.time()-start\n",
    "print(time_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2a6de2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y=model.predict(x_test, batch_size=100)\n",
    "#返回索引\n",
    "pred_yindex=np.argmax(pred_y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b52984fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       542\n",
      "           1       0.93      0.93      0.93       554\n",
      "           2       0.95      0.94      0.94       536\n",
      "           3       0.91      1.00      0.95       525\n",
      "           4       0.97      0.88      0.92       531\n",
      "\n",
      "    accuracy                           0.95      2688\n",
      "   macro avg       0.95      0.95      0.95      2688\n",
      "weighted avg       0.95      0.95      0.95      2688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "print(sklearn.metrics.classification_report(te_label,pred_yindex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62a99f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2233/2233 [==============================] - 0s 206us/sample - loss: 0.3405 - sparse_categorical_accuracy: 0.9386\n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "score = model.evaluate(x_test, te_label, batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c653888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       462\n",
      "           1       0.93      0.90      0.92       450\n",
      "           2       0.93      0.93      0.93       450\n",
      "           3       0.93      0.96      0.94       422\n",
      "           4       0.95      0.92      0.93       449\n",
      "\n",
      "    accuracy                           0.94      2233\n",
      "   macro avg       0.94      0.94      0.94      2233\n",
      "weighted avg       0.94      0.94      0.94      2233\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(te_label,pred_yindex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74076b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2689/2689 [==============================] - 1s 201us/sample - loss: 0.2684 - sparse_categorical_accuracy: 0.9517\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       529\n",
      "           1       0.90      0.93      0.92       544\n",
      "           2       0.95      0.97      0.96       549\n",
      "           3       0.99      0.95      0.97       526\n",
      "           4       0.93      0.92      0.93       541\n",
      "\n",
      "    accuracy                           0.95      2689\n",
      "   macro avg       0.95      0.95      0.95      2689\n",
      "weighted avg       0.95      0.95      0.95      2689\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "score = model.evaluate(x_test, te_label, batch_size=30)\n",
    "print(sklearn.metrics.classification_report(te_label,pred_yindex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60090cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2087/2087 [==============================] - 0s 210us/sample - loss: 0.2914 - sparse_categorical_accuracy: 0.9420\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       424\n",
      "           1       0.91      0.91      0.91       409\n",
      "           2       0.95      0.96      0.95       424\n",
      "           3       0.92      0.98      0.95       404\n",
      "           4       0.94      0.88      0.91       426\n",
      "\n",
      "    accuracy                           0.94      2087\n",
      "   macro avg       0.94      0.94      0.94      2087\n",
      "weighted avg       0.94      0.94      0.94      2087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "score = model.evaluate(x_test, te_label, batch_size=30)\n",
    "print(sklearn.metrics.classification_report(te_label,pred_yindex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81fa8d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2159/2159 [==============================] - 0s 205us/sample - loss: 0.2663 - sparse_categorical_accuracy: 0.9444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       413\n",
      "           1       0.93      0.92      0.93       450\n",
      "           2       0.95      0.97      0.96       438\n",
      "           3       0.93      0.96      0.95       430\n",
      "           4       0.93      0.87      0.90       428\n",
      "\n",
      "    accuracy                           0.94      2159\n",
      "   macro avg       0.94      0.94      0.94      2159\n",
      "weighted avg       0.94      0.94      0.94      2159\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "score = model.evaluate(x_test, te_label, batch_size=30)\n",
    "print(sklearn.metrics.classification_report(te_label,pred_yindex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5ef15863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2279/2279 [==============================] - 1s 255us/sample - loss: 0.2145 - sparse_categorical_accuracy: 0.9509\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       447\n",
      "           1       0.95      0.91      0.93       477\n",
      "           2       0.94      0.98      0.96       445\n",
      "           3       0.93      0.96      0.94       438\n",
      "           4       0.96      0.93      0.95       472\n",
      "\n",
      "    accuracy                           0.95      2279\n",
      "   macro avg       0.95      0.95      0.95      2279\n",
      "weighted avg       0.95      0.95      0.95      2279\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#6\n",
    "score = model.evaluate(x_test, te_label, batch_size=30)\n",
    "print(sklearn.metrics.classification_report(te_label,pred_yindex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03b46f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2377/2377 [==============================] - 1s 216us/sample - loss: 0.1994 - sparse_categorical_accuracy: 0.9584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       489\n",
      "           1       0.94      0.96      0.95       463\n",
      "           2       0.95      0.97      0.96       488\n",
      "           3       0.94      0.96      0.95       463\n",
      "           4       0.97      0.91      0.94       474\n",
      "\n",
      "    accuracy                           0.96      2377\n",
      "   macro avg       0.96      0.96      0.96      2377\n",
      "weighted avg       0.96      0.96      0.96      2377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "score = model.evaluate(x_test, te_label, batch_size=30)\n",
    "print(sklearn.metrics.classification_report(te_label,pred_yindex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cfc20d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2170/2170 [==============================] - 1s 394us/sample - loss: 0.2455 - sparse_categorical_accuracy: 0.9456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       443\n",
      "           1       0.91      0.96      0.93       430\n",
      "           2       0.96      0.94      0.95       438\n",
      "           3       0.95      0.91      0.93       432\n",
      "           4       0.93      0.93      0.93       427\n",
      "\n",
      "    accuracy                           0.95      2170\n",
      "   macro avg       0.95      0.95      0.95      2170\n",
      "weighted avg       0.95      0.95      0.95      2170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "score = model.evaluate(x_test, te_label, batch_size=30)\n",
    "print(sklearn.metrics.classification_report(te_label,pred_yindex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8960f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2200/2200 [==============================] - 1s 384us/sample - loss: 0.2894 - sparse_categorical_accuracy: 0.9373\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       458\n",
      "           1       0.89      0.90      0.89       430\n",
      "           2       0.94      0.96      0.95       425\n",
      "           3       0.95      0.95      0.95       459\n",
      "           4       0.94      0.89      0.92       428\n",
      "\n",
      "    accuracy                           0.94      2200\n",
      "   macro avg       0.94      0.94      0.94      2200\n",
      "weighted avg       0.94      0.94      0.94      2200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#9\n",
    "score = model.evaluate(x_test, te_label, batch_size=30)\n",
    "print(sklearn.metrics.classification_report(te_label,pred_yindex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ef41b6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2476/2476 [==============================] - 1s 217us/sample - loss: 0.1818 - sparse_categorical_accuracy: 0.9588\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       503\n",
      "           1       0.92      0.94      0.93       508\n",
      "           2       0.97      0.96      0.97       474\n",
      "           3       0.95      0.97      0.96       481\n",
      "           4       0.97      0.94      0.95       510\n",
      "\n",
      "    accuracy                           0.96      2476\n",
      "   macro avg       0.96      0.96      0.96      2476\n",
      "weighted avg       0.96      0.96      0.96      2476\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "score = model.evaluate(x_test, te_label, batch_size=30)\n",
    "print(sklearn.metrics.classification_report(te_label,pred_yindex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "79bd20fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2433/2433 [==============================] - 1s 212us/sample - loss: 0.1895 - sparse_categorical_accuracy: 0.9601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       499\n",
      "           1       0.96      0.90      0.93       496\n",
      "           2       0.97      0.98      0.97       482\n",
      "           3       0.93      0.98      0.95       468\n",
      "           4       0.95      0.94      0.95       488\n",
      "\n",
      "    accuracy                           0.96      2433\n",
      "   macro avg       0.96      0.96      0.96      2433\n",
      "weighted avg       0.96      0.96      0.96      2433\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#11\n",
    "score = model.evaluate(x_test, te_label, batch_size=30)\n",
    "print(sklearn.metrics.classification_report(te_label,pred_yindex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c6e384c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1974/1974 [==============================] - 0s 214us/sample - loss: 0.2652 - sparse_categorical_accuracy: 0.9336\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       392\n",
      "           1       0.89      0.91      0.90       390\n",
      "           2       0.95      0.95      0.95       417\n",
      "           3       0.94      0.94      0.94       381\n",
      "           4       0.92      0.88      0.90       394\n",
      "\n",
      "    accuracy                           0.93      1974\n",
      "   macro avg       0.93      0.93      0.93      1974\n",
      "weighted avg       0.93      0.93      0.93      1974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#12\n",
    "score = model.evaluate(x_test, te_label, batch_size=30)\n",
    "print(sklearn.metrics.classification_report(te_label,pred_yindex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ebe23b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2741/2741 [==============================] - 1s 194us/sample - loss: 0.1941 - sparse_categorical_accuracy: 0.9566\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       552\n",
      "           1       0.90      0.97      0.94       515\n",
      "           2       0.96      0.95      0.95       588\n",
      "           3       0.97      0.95      0.96       542\n",
      "           4       0.95      0.93      0.94       544\n",
      "\n",
      "    accuracy                           0.96      2741\n",
      "   macro avg       0.96      0.96      0.96      2741\n",
      "weighted avg       0.96      0.96      0.96      2741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#13\n",
    "score = model.evaluate(x_test, te_label, batch_size=30)\n",
    "print(sklearn.metrics.classification_report(te_label,pred_yindex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8e327d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2440/2440 [==============================] - 1s 360us/sample - loss: 0.2160 - sparse_categorical_accuracy: 0.9578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       505\n",
      "           1       0.94      0.94      0.94       484\n",
      "           2       0.97      0.95      0.96       501\n",
      "           3       0.94      0.96      0.95       458\n",
      "           4       0.93      0.95      0.94       492\n",
      "\n",
      "    accuracy                           0.96      2440\n",
      "   macro avg       0.96      0.96      0.96      2440\n",
      "weighted avg       0.96      0.96      0.96      2440\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#14\n",
    "score = model.evaluate(x_test, te_label, batch_size=30)\n",
    "print(sklearn.metrics.classification_report(te_label,pred_yindex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af5b77cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2107/2107 [==============================] - 0s 216us/sample - loss: 0.2061 - sparse_categorical_accuracy: 0.9473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       438\n",
      "           1       0.95      0.90      0.92       422\n",
      "           2       0.97      0.96      0.96       415\n",
      "           3       0.89      0.95      0.92       415\n",
      "           4       0.95      0.95      0.95       417\n",
      "\n",
      "    accuracy                           0.95      2107\n",
      "   macro avg       0.95      0.95      0.95      2107\n",
      "weighted avg       0.95      0.95      0.95      2107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#15\n",
    "score = model.evaluate(x_test, te_label, batch_size=30)\n",
    "print(sklearn.metrics.classification_report(te_label,pred_yindex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb32985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37tf]",
   "language": "python",
   "name": "conda-env-py37tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
